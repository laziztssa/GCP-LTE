{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d25079-a820-4f50-b8b6-b5d5b0d93b98",
   "metadata": {},
   "source": [
    "### **Importation des bibliothÃ¨ques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a68df27-36c7-4801-ac17-8f7a8fca2479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0ca43c-aced-4ed9-ac1a-cdebca9595e0",
   "metadata": {},
   "source": [
    "###  **Initialize GCS & BigQuery Clients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3336fe3-b356-4982-b86b-75103cb4adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "storage_client = storage.Client()\n",
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d3ab6-be7b-4356-9ca4-7d41d747fe66",
   "metadata": {},
   "source": [
    "### **session Pyspark** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa71eab4-b43f-4945-9bf6-3da269459220",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"HospitalAMySQLToLanding\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb65216-12aa-49c0-a0bd-59fb62a4b58b",
   "metadata": {},
   "source": [
    "### **Configuration du Google Cloud Storage (GCS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9834e0b9-db97-44b2-82e1-1f76a52e1e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_BUCKET = \"healthcare-bucket-lte\"\n",
    "HOSPITAL_NAME = \"hospital-a\"\n",
    "LANDING_PATH = f\"gs://{GCS_BUCKET}/landing/{HOSPITAL_NAME}/\"\n",
    "ARCHIVE_PATH = f\"gs://{GCS_BUCKET}/landing/{HOSPITAL_NAME}/archive\"\n",
    "CONFIG_FILE_PATH = f\"gs://{GCS_BUCKET}/configs/load_config.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df3d6fb-0723-4160-b84a-0db5f8ad6c6b",
   "metadata": {},
   "source": [
    "### **Configuration du BigQuery**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b681708-a2ab-4579-a858-b72727dbdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_PROJECT = \"gcp-demo-lte\" \n",
    "BQ_AUDIT_TABLE = f\"{BQ_PROJECT}.temp_dataset.audit_log\"\n",
    "BQ_LOG_TABLE = f\"{BQ_PROJECT}.temp_dataset.pipeline_logs\"\n",
    "BQ_TEMP_PATH = f\"{GCS_BUCKET}/temp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c996fb-0fdf-43bd-b982-8146f00c11d8",
   "metadata": {},
   "source": [
    "### **MySql Configuration** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb747df-db85-4742-a41b-cc635a9e0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_CONFIG = {\n",
    "    \"url\": \"jdbc:mysql://34.59.213.195:3306/hospital_a_db?useSSL=false&allowPublicKeyRetrieval=true\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\",\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"Laziz04092021@\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bdeeb6-1c67-454e-a284-67016a03412e",
   "metadata": {},
   "source": [
    "### **Mecanisme de sauvgarde de log** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a472f66c-9972-4eb9-ad17-ef7d601ba0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_entries = []   # les stocker dans un dictionnaire avant de les charger \n",
    "\n",
    "def log_event(event_type, message, table=None):\n",
    "    \"\"\"Log an event and store it in the log list\"\"\"\n",
    "    log_entry = {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        \"event_type\": event_type,\n",
    "        \"message\": message,\n",
    "        \"table\": table\n",
    "    }\n",
    "    log_entries.append(log_entry)\n",
    "    print(f\"[{log_entry['timestamp']}] {event_type} - {message}\")  # Print for visibility\n",
    "    \n",
    "#-------------------------------------------------------------------------------------------   \n",
    "\n",
    "def save_logs_to_gcs():\n",
    "    \"\"\"Save logs to a JSON file and upload to GCS\"\"\"\n",
    "    log_filename = f\"pipeline_log_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}.json\"\n",
    "    log_filepath = f\"temp/pipeline_logs/{log_filename}\"  \n",
    "    \n",
    "    json_data = json.dumps(log_entries, indent=4)\n",
    "\n",
    "    # Get GCS bucket\n",
    "    bucket = storage_client.bucket(GCS_BUCKET)\n",
    "    blob = bucket.blob(log_filepath)\n",
    "    \n",
    "    # Upload JSON data as a file\n",
    "    blob.upload_from_string(json_data, content_type=\"application/json\")\n",
    "\n",
    "    print(f\"âœ… Logs successfully saved to GCS at gs://{GCS_BUCKET}/{log_filepath}\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------------    \n",
    "def save_logs_to_bigquery():\n",
    "    \"\"\"Save logs to BigQuery\"\"\"\n",
    "    if log_entries:\n",
    "        log_df = spark.createDataFrame(log_entries)\n",
    "        log_df.write.format(\"bigquery\") \\\n",
    "            .option(\"table\", BQ_LOG_TABLE) \\\n",
    "            .option(\"temporaryGcsBucket\", BQ_TEMP_PATH) \\\n",
    "            .mode(\"append\") \\\n",
    "            .save()\n",
    "        print(\"âœ… Logs stored in BigQuery for future analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659c42b-d035-4df7-982e-908d74bf6a84",
   "metadata": {},
   "source": [
    "### **Fonction pour archiver les fichier deja traitÃ©s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ef25fd-c821-4ef5-882c-2ae026474e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_existing_table_to_archive(table):\n",
    "    blobs = list(storage_client.bucket(GCS_BUCKET).list_blobs(prefix=f\"landing/{HOSPITAL_NAME}/{table}\"))\n",
    "    existing_files =  [blob.name for blob in blobs if blob.name.endswith(\".json\")]\n",
    "\n",
    "    \n",
    "    if not existing_files:\n",
    "        log_event(\"INFO\", f\"No exiting files for table {table}\")\n",
    "        return\n",
    "    \n",
    "    for file in existing_files:\n",
    "        source_blob =  storage_client.bucket(GCS_BUCKET).blob(file)\n",
    "        \n",
    "        # Extraire la date du fichier \n",
    "        \n",
    "        date_part = file.split(\"_\")[-1].split(\".\")[0]\n",
    "        year, month , day = date_part[-4:], date_part[2:4], date_part[:2]\n",
    "        \n",
    "        \n",
    "        # Deplacer vers l'archive\n",
    "        \n",
    "        archive_path =  f\"landing/{HOSPITAL_NAME}/archive/{table}/{year}/{month}/{day}/{file.split('/')[-1]}\"\n",
    "        destinantion_blob = storage_client.bucket(GCS_BUCKET).blob(archive_path)\n",
    "        \n",
    "        \n",
    "        # Copier le fichier dans l'archive et supprfession de l'original \n",
    "        \n",
    "        storage_client.bucket(GCS_BUCKET).copy_blob(source_blob, storage_client.bucket(GCS_BUCKET), destinantion_blob.name)\n",
    "        source_blob.delete()\n",
    "        \n",
    "        log_event(\"INFO\", f\"Moved {file} to {archive_path}\", table = table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ec493f-2438-49d9-bd9f-e76c4e6834cf",
   "metadata": {},
   "source": [
    "### **Function to Get Latest Watermark from BigQuery Audit Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c7ca583-0cb8-4b60-8ecb-dce28390a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_watermark(table_name):\n",
    "    query = f\"\"\"\n",
    "        SELECT MAX(load_timestamp) AS latest_timestamp\n",
    "        FROM `{BQ_AUDIT_TABLE}`\n",
    "        WHERE tablename = '{table_name}' and data_source = \"hospital_a_db\"\n",
    "    \"\"\"\n",
    "    query_job = bq_client.query(query)\n",
    "    result = query_job.result()\n",
    "    for row in result:\n",
    "        return row.latest_timestamp if row.latest_timestamp else \"1900-01-01 00:00:00\"\n",
    "    return \"1900-01-01 00:00:00\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ffd8f-1a3f-4933-abd2-cd34c6e96ee8",
   "metadata": {},
   "source": [
    "### **Function to Extract Data from MySQL and Save to GCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5dd7d74-0422-43d1-94d4-5ded1edbb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_save_to_landing(table, load_type, watermark_col):\n",
    "    try:\n",
    "        last_watermark = get_latest_watermark(table) if load_type.lower() == \"incremental\" else None\n",
    "        log_event(\"INFO\", f\"Latest watermark for {table}: {last_watermark}\", table=table)\n",
    "\n",
    "        query = f\"(SELECT * FROM {table}) AS t\" if load_type.lower() == \"full\" else \\\n",
    "                f\"(SELECT * FROM {table} WHERE {watermark_col} > '{last_watermark}') AS t\"\n",
    "\n",
    "        df = (spark.read.format(\"jdbc\")\n",
    "                .option(\"url\", MYSQL_CONFIG[\"url\"])\n",
    "                .option(\"user\", MYSQL_CONFIG[\"user\"])\n",
    "                .option(\"password\", MYSQL_CONFIG[\"password\"])\n",
    "                .option(\"driver\", MYSQL_CONFIG[\"driver\"])\n",
    "                .option(\"dbtable\", query)\n",
    "                .load())\n",
    "\n",
    "        log_event(\"SUCCESS\", f\"âœ… Successfully extracted data from {table}\", table=table)\n",
    "\n",
    "        today = datetime.datetime.today().strftime('%d%m%Y')\n",
    "        JSON_FILE_PATH = f\"landing/{HOSPITAL_NAME}/{table}/{table}_{today}.json\"\n",
    "\n",
    "        bucket = storage_client.bucket(GCS_BUCKET)\n",
    "        blob = bucket.blob(JSON_FILE_PATH)\n",
    "        blob.upload_from_string(df.toPandas().to_json(orient=\"records\", lines=True), content_type=\"application/json\")\n",
    "\n",
    "        log_event(\"SUCCESS\", f\"âœ… JSON file successfully written to gs://{GCS_BUCKET}/{JSON_FILE_PATH}\", table=table)\n",
    "        \n",
    "        # Insert Audit Entry\n",
    "        audit_df = spark.createDataFrame([\n",
    "            (\"hospital_a_db\", table, load_type, df.count(), datetime.datetime.now(), \"SUCCESS\")], \n",
    "            [\"data_source\", \"tablename\", \"load_type\", \"record_count\", \"load_timestamp\", \"status\"])\n",
    "\n",
    "        (audit_df.write.format(\"bigquery\")\n",
    "            .option(\"table\", BQ_AUDIT_TABLE)\n",
    "            .option(\"temporaryGcsBucket\", GCS_BUCKET)\n",
    "            .mode(\"append\")\n",
    "            .save())\n",
    "\n",
    "        log_event(\"SUCCESS\", f\"âœ… Audit log updated for {table}\", table=table)\n",
    "\n",
    "    except Exception as e:\n",
    "        log_event(\"ERROR\", f\"Error processing {table}: {str(e)}\", table=table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9c418-b2f4-4f02-98f1-a77c2c7aa0ed",
   "metadata": {},
   "source": [
    "### **Fonction de lecture de fichier de depuis le GCS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ddca35c-4cd4-48fa-9141-788aa3bc1323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config_file():\n",
    "    df =  spark.read.csv(CONFIG_FILE_PATH, header = True)\n",
    "    log_event(\"INFO\", \"Successfully read the config file\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e8084-c60f-4108-9792-0060b6973e6f",
   "metadata": {},
   "source": [
    "### **lecture du config file + chargement dans lanfing + archivage des fichiers** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba89ea5-bcea-47ac-9bca-608a06c7a92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:09:24.703875] INFO - Successfully read the config file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:09:27.861334] INFO - No exiting files for table encounters\n",
      "[2025-05-23T13:09:28.707001] INFO - Latest watermark for encounters: 1900-01-01 00:00:00\n",
      "[2025-05-23T13:09:29.565467] SUCCESS - âœ… Successfully extracted data from encounters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:09:32.495645] SUCCESS - âœ… JSON file successfully written to gs://healthcare-bucket-lte/landing/hospital-a/encounters/encounters_23052025.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:09:46.916211] SUCCESS - âœ… Audit log updated for encounters\n",
      "[2025-05-23T13:09:46.942896] INFO - No exiting files for table patients\n",
      "[2025-05-23T13:09:47.843017] INFO - Latest watermark for patients: 1900-01-01 00:00:00\n",
      "[2025-05-23T13:09:48.098240] SUCCESS - âœ… Successfully extracted data from patients\n",
      "[2025-05-23T13:09:49.206460] SUCCESS - âœ… JSON file successfully written to gs://healthcare-bucket-lte/landing/hospital-a/patients/patients_23052025.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:09:56.961704] SUCCESS - âœ… Audit log updated for patients\n",
      "[2025-05-23T13:09:56.990217] INFO - No exiting files for table transactions\n",
      "[2025-05-23T13:09:57.900641] INFO - Latest watermark for transactions: 1900-01-01 00:00:00\n",
      "[2025-05-23T13:09:58.174219] SUCCESS - âœ… Successfully extracted data from transactions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:10:00.127317] SUCCESS - âœ… JSON file successfully written to gs://healthcare-bucket-lte/landing/hospital-a/transactions/transactions_23052025.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:10:07.424552] SUCCESS - âœ… Audit log updated for transactions\n",
      "[2025-05-23T13:10:07.447150] INFO - No exiting files for table providers\n",
      "[2025-05-23T13:10:07.447236] INFO - Latest watermark for providers: None\n",
      "[2025-05-23T13:10:07.691462] SUCCESS - âœ… Successfully extracted data from providers\n",
      "[2025-05-23T13:10:08.264017] SUCCESS - âœ… JSON file successfully written to gs://healthcare-bucket-lte/landing/hospital-a/providers/providers_23052025.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:10:15.163739] SUCCESS - âœ… Audit log updated for providers\n",
      "[2025-05-23T13:10:15.191169] INFO - No exiting files for table departments\n",
      "[2025-05-23T13:10:15.191335] INFO - Latest watermark for departments: None\n",
      "[2025-05-23T13:10:15.427843] SUCCESS - âœ… Successfully extracted data from departments\n",
      "[2025-05-23T13:10:15.939792] SUCCESS - âœ… JSON file successfully written to gs://healthcare-bucket-lte/landing/hospital-a/departments/departments_23052025.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-23T13:10:22.819599] SUCCESS - âœ… Audit log updated for departments\n",
      "âœ… Logs successfully saved to GCS at gs://healthcare-bucket-lte/temp/pipeline_logs/pipeline_log_20250523131022.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Logs stored in BigQuery for future analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 58816)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/miniconda3/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/miniconda3/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/miniconda3/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/miniconda3/lib/python3.8/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/spark/python/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/lib/spark/python/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/usr/lib/spark/python/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/lib/spark/python/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config_df = read_config_file()\n",
    "\n",
    "for row in config_df.collect():\n",
    "    if row[\"is_active\"] == '1' and row[\"datasource\"] == 'hospital_a_db':\n",
    "        db, src, table, load_type, watermark, _,targetpath = row\n",
    "        move_existing_table_to_archive(table)\n",
    "        extract_and_save_to_landing(table, load_type, watermark)\n",
    "\n",
    "save_logs_to_gcs()\n",
    "save_logs_to_bigquery()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}