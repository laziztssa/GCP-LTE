{"cells": [{"cell_type": "code", "execution_count": null, "id": "012ff1e2-b0b4-4921-a5bd-6a617092b592", "metadata": {}, "outputs": [], "source": "import airflow\nfrom airflow import DAG\nfrom datetime import timedelta\nfrom airflow.utils.dates import days_ago\nfrom airflow.operators.dagrun_operator import TriggerDagRunOperator\n\n# Define default arguments\nARGS = {\n    \"owner\": \"SHAIK SAIDHUL\",\n    \"start_date\": days_ago(1),\n    \"depends_on_past\": False,\n    \"email_on_failure\": False,\n    \"email_on_retry\": False,\n    \"email\": [\"***@gmail.com\"],\n    \"email_on_success\": False,\n    \"retries\": 1,\n    \"retry_delay\": timedelta(minutes=5)\n}\n\n# Define the parent DAG\nwith DAG(\n    dag_id=\"parent_dag\",\n    schedule_interval=\"0 5 * * *\",\n    description=\"Parent DAG to trigger PySpark and BigQuery DAGs\",\n    default_args=ARGS,\n    tags=[\"parent\", \"orchestration\", \"etl\"]\n) as dag:\n\n    # Task to trigger PySpark DAG\n    trigger_pyspark_dag = TriggerDagRunOperator(\n        task_id=\"trigger_pyspark_dag\",\n        trigger_dag_id=\"pyspark_dag\",\n        wait_for_completion=True,\n    )\n\n    # Task to trigger BigQuery DAG\n    trigger_bigquery_dag = TriggerDagRunOperator(\n        task_id=\"trigger_bigquery_dag\",\n        trigger_dag_id=\"bigquery_dag\",\n        wait_for_completion=True,\n    )\n\n# Define dependencies\ntrigger_pyspark_dag >> trigger_bigquery_dag"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}